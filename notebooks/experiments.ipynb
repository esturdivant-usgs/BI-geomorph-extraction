{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import CoastalVarExtractor.functions_warcpy as fwa\n",
    "import CoastalVarExtractor.functions as fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: FireIsland\n",
      "year: 2012\n",
      "setvars.py initialized variables.\n"
     ]
    }
   ],
   "source": [
    "from CoastalVarExtractor.setvars import *\n",
    "\n",
    "extendedTrans = os.path.join(home, 'fiis_trans')\n",
    "extTrans_tidy = os.path.join(home, 'tidyTrans')\n",
    "\n",
    "inletLines = os.path.join(home, 'inletLines')\n",
    "ShorelinePts = os.path.join(home, 'SLpts_utm')\n",
    "dlPts = os.path.join(home, 'DLpts_utm')\n",
    "dhPts = os.path.join(home, 'DHpts_utm')\n",
    "armorLines = os.path.join(home, 'armorLines')\n",
    "elevGrid = os.path.join(home, 'DEM')\n",
    "elevGrid_5m = os.path.join(home, 'DEM_5m')\n",
    "barrierBoundary = os.path.join(home, 'bndpoly_2sl')  \n",
    "shoreline = os.path.join(home, 'ShoreBetweenInlets')\n",
    "\n",
    "SubType = os.path.join(home, 'FI12_SubType')\n",
    "VegType = os.path.join(home, 'FI12_VegType')\n",
    "VegDens = os.path.join(home, 'FI12_VegDen')\n",
    "GeoSet = os.path.join(home, 'FI12_GeoSet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import data from xls \n",
    "# File name\n",
    "xls_path = r\"\\\\IGSAGIEGGS-CSGG\\Thieler_Group\\Commons_DeepDive\\DeepDive\\NewYork\\AnthropogenicData\"\n",
    "xls_name = \"FI2012_trans_5mPtsUpCombinedsubFixALL2.xlsx\"\n",
    "\n",
    "xltbl = pd.read_excel(os.path.join(xls_path, xls_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID_1</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>BASELINEID</th>\n",
       "      <th>TRANSORDER</th>\n",
       "      <th>PROCTIME</th>\n",
       "      <th>AUTOGEN</th>\n",
       "      <th>ENDX</th>\n",
       "      <th>ENDY</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>SHAPE_LENG</th>\n",
       "      <th>...</th>\n",
       "      <th>Dist_MHWbay</th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>DistSegDH</th>\n",
       "      <th>DistSegDL</th>\n",
       "      <th>DistSegArm</th>\n",
       "      <th>PointZ</th>\n",
       "      <th>PointSlp</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "      <th>Construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.91820</td>\n",
       "      <td>9.842591</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1.19412</td>\n",
       "      <td>7.487503</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.85836</td>\n",
       "      <td>5.800764</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>1.05932</td>\n",
       "      <td>6.581713</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>-99999</td>\n",
       "      <td>1</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>358.75</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>0.88016</td>\n",
       "      <td>10.083154</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID_1  OBJECTID  BASELINEID  TRANSORDER  PROCTIME  AUTOGEN     ENDX  \\\n",
       "0           1      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "1           2      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "2           3      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "3           4      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "4           5      3519      -99999           1  -99999.0   -99999 -99999.0   \n",
       "\n",
       "      ENDY  AZIMUTH  SHAPE_LENG      ...       Dist_MHWbay  SplitSort  \\\n",
       "0 -99999.0   358.75    -99999.0      ...          -99999.0          1   \n",
       "1 -99999.0   358.75    -99999.0      ...          -99999.0          2   \n",
       "2 -99999.0   358.75    -99999.0      ...          -99999.0          3   \n",
       "3 -99999.0   358.75    -99999.0      ...          -99999.0          4   \n",
       "4 -99999.0   358.75    -99999.0      ...          -99999.0          5   \n",
       "\n",
       "   DistSegDH  DistSegDL  DistSegArm   PointZ   PointSlp  Development  \\\n",
       "0   -99999.0   -99999.0    -99999.0  0.91820   9.842591          111   \n",
       "1   -99999.0   -99999.0    -99999.0  1.19412   7.487503          111   \n",
       "2   -99999.0   -99999.0    -99999.0  0.85836   5.800764          111   \n",
       "3   -99999.0   -99999.0    -99999.0  1.05932   6.581713          111   \n",
       "4   -99999.0   -99999.0    -99999.0  0.88016  10.083154          111   \n",
       "\n",
       "   Nourishment  Construction  \n",
       "0          111           111  \n",
       "1          111           111  \n",
       "2          111           111  \n",
       "3          111           111  \n",
       "4          111           111  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xltbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID_1', 'OBJECTID', 'BASELINEID', 'TRANSORDER', 'PROCTIME',\n",
       "       'AUTOGEN', 'ENDX', 'ENDY', 'AZIMUTH', 'SHAPE_LENG', 'TRANSECTID', 'LRR',\n",
       "       'LR2', 'LSE', 'LCI90', 'TID2', 'LRR2', 'LR22', 'LSE2', 'LCI902',\n",
       "       'SL_Lon', 'SL_Lat', 'SL_easting', 'SL_northing', 'Bslope', 'Arm_Lon',\n",
       "       'Arm_Lat', 'Arm_easting', 'Arm_northing', 'Arm_z', 'DH_Lon', 'DH_Lat',\n",
       "       'DH_easting', 'DH_northing', 'DH_z', 'DL_Lon', 'DL_Lat', 'DL_easting',\n",
       "       'DL_northing', 'DL_z', 'DL_zMHW', 'DH_zMHW', 'Arm_zMHW', 'DistDH',\n",
       "       'DistDL', 'DistArm', 'Dist2Inlet', 'WidthLand', 'WidthFull',\n",
       "       'WidthPart', 'Source_beachwidth', 'MLW_easting', 'MLW_northing',\n",
       "       'beach_h_MLW', 'beachWidth_MLW', 'ORIG_OID', 'seg_y', 'seg_x',\n",
       "       'Dist_Seg', 'Dist_MHWbay', 'SplitSort', 'DistSegDH', 'DistSegDL',\n",
       "       'DistSegArm', 'PointZ', 'PointSlp', 'Development', 'Nourishment',\n",
       "       'Construction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xltbl.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join anthro data to transects\n",
    "\n",
    "1. Convert xls spreadsheet to points \n",
    "2. Select the first points along each transects and create new FC\n",
    "3. Spatial Join the new FC to the updated transects \n",
    "    - one to one\n",
    "    - keep all target features\n",
    "    - keep only the ID fields and the three anthro fields (and the transect fields [LRR, etc.]?)\n",
    "    - intersect\n",
    "\n",
    "4. Join the transect values to the pts based on sort_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_w_anthro = os.path.join(arcpy.env.workspace, 'fiis_trans_wAnthro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n"
     ]
    }
   ],
   "source": [
    "trans_df2 = fwa.FCtoDF(tr_w_anthro, id_fld=tID_fld, dffields=['Development', 'Nourishment','Construction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>GeoSet</th>\n",
       "      <th>seg_x</th>\n",
       "      <th>seg_y</th>\n",
       "      <th>SubType</th>\n",
       "      <th>VegDens</th>\n",
       "      <th>VegType</th>\n",
       "      <th>ptSlp</th>\n",
       "      <th>ptZ</th>\n",
       "      <th>sort_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ub_feat</th>\n",
       "      <th>Dist2Inlet</th>\n",
       "      <th>WidthFull</th>\n",
       "      <th>WidthLand</th>\n",
       "      <th>WidthPart</th>\n",
       "      <th>mean_Zmhw</th>\n",
       "      <th>max_Zmhw</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642131.5400</td>\n",
       "      <td>4.498927e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.445196</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642133.1304</td>\n",
       "      <td>4.498932e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.445196</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642134.7209</td>\n",
       "      <td>4.498937e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.459952</td>\n",
       "      <td>0.39028</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>642115.6352</td>\n",
       "      <td>4.498880e+06</td>\n",
       "      <td>7777.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.083154</td>\n",
       "      <td>0.88016</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>642117.2257</td>\n",
       "      <td>4.498885e+06</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.088981</td>\n",
       "      <td>0.86376</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>65.098101</td>\n",
       "      <td>0.435538</td>\n",
       "      <td>0.81284</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SplitSort  GeoSet        seg_x         seg_y  SubType  VegDens  VegType  \\\n",
       "0          0     1.0  642131.5400  4.498927e+06   4444.0    111.0     11.0   \n",
       "1          1     1.0  642133.1304  4.498932e+06   4444.0    111.0     11.0   \n",
       "2          2     1.0  642134.7209  4.498937e+06   4444.0    111.0     11.0   \n",
       "3          3     2.0  642115.6352  4.498880e+06   7777.0    666.0     77.0   \n",
       "4          4     1.0  642117.2257  4.498885e+06   4444.0    111.0     11.0   \n",
       "\n",
       "       ptSlp      ptZ sort_ID     ...       ub_feat  Dist2Inlet  WidthFull  \\\n",
       "0   4.445196  0.68200       1     ...           NaN         NaN  65.098101   \n",
       "1   4.445196  0.68200       1     ...           NaN         NaN  65.098101   \n",
       "2   7.459952  0.39028       1     ...           NaN         NaN  65.098101   \n",
       "3  10.083154  0.88016       1     ...           NaN         NaN  65.098101   \n",
       "4  10.088981  0.86376       1     ...           NaN         NaN  65.098101   \n",
       "\n",
       "   WidthLand  WidthPart  mean_Zmhw  max_Zmhw  Construction  Development  \\\n",
       "0  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "1  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "2  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "3  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "4  65.098101  65.098101   0.435538   0.81284         111.0        111.0   \n",
       "\n",
       "   Nourishment  \n",
       "0        111.0  \n",
       "1        111.0  \n",
       "2        111.0  \n",
       "3        111.0  \n",
       "4        111.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get existing DFs\n",
    "pts_df = pd.read_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))\n",
    "trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))\n",
    "\n",
    "# Join anthro fields to trans and points DFs\n",
    "trans_df = fun.join_columns(trans_df, trans_df2) \n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "\n",
    "# Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_anthro.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'_anthro.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SplitSort</th>\n",
       "      <th>seg_x</th>\n",
       "      <th>seg_y</th>\n",
       "      <th>Dist_Seg</th>\n",
       "      <th>Dist_MHWbay</th>\n",
       "      <th>DistSegDH</th>\n",
       "      <th>DistSegDL</th>\n",
       "      <th>DistSegArm</th>\n",
       "      <th>ptZ</th>\n",
       "      <th>ptSlp</th>\n",
       "      <th>...</th>\n",
       "      <th>WidthLand</th>\n",
       "      <th>WidthFull</th>\n",
       "      <th>uBW</th>\n",
       "      <th>uBH</th>\n",
       "      <th>ub_feat</th>\n",
       "      <th>mean_Zmhw</th>\n",
       "      <th>max_Zmhw</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Development</th>\n",
       "      <th>Nourishment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66615</th>\n",
       "      <td>66615</td>\n",
       "      <td>677018.1595</td>\n",
       "      <td>4.509975e+06</td>\n",
       "      <td>230.000032</td>\n",
       "      <td>82.220969</td>\n",
       "      <td>143.009575</td>\n",
       "      <td>149.259519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60388</td>\n",
       "      <td>2.552202</td>\n",
       "      <td>...</td>\n",
       "      <td>312.221001</td>\n",
       "      <td>312.221001</td>\n",
       "      <td>80.787403</td>\n",
       "      <td>3.090523</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.957232</td>\n",
       "      <td>4.469680</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85619</th>\n",
       "      <td>85619</td>\n",
       "      <td>687214.1370</td>\n",
       "      <td>4.514490e+06</td>\n",
       "      <td>345.696325</td>\n",
       "      <td>-131.024561</td>\n",
       "      <td>229.025318</td>\n",
       "      <td>240.263141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35092</td>\n",
       "      <td>0.961539</td>\n",
       "      <td>...</td>\n",
       "      <td>749.924166</td>\n",
       "      <td>855.620515</td>\n",
       "      <td>105.471719</td>\n",
       "      <td>4.944896</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.591762</td>\n",
       "      <td>7.122921</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66511</th>\n",
       "      <td>66511</td>\n",
       "      <td>677044.7910</td>\n",
       "      <td>4.509796e+06</td>\n",
       "      <td>55.000040</td>\n",
       "      <td>286.701757</td>\n",
       "      <td>32.017383</td>\n",
       "      <td>25.841729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81084</td>\n",
       "      <td>2.832443</td>\n",
       "      <td>...</td>\n",
       "      <td>341.701797</td>\n",
       "      <td>341.701797</td>\n",
       "      <td>80.572297</td>\n",
       "      <td>2.878211</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.657066</td>\n",
       "      <td>3.999680</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31938</th>\n",
       "      <td>31938</td>\n",
       "      <td>657490.3763</td>\n",
       "      <td>4.501733e+06</td>\n",
       "      <td>434.999996</td>\n",
       "      <td>137.250023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>572.250019</td>\n",
       "      <td>572.250019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.859720</td>\n",
       "      <td>111.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87919</th>\n",
       "      <td>87919</td>\n",
       "      <td>688190.4957</td>\n",
       "      <td>4.514639e+06</td>\n",
       "      <td>270.000020</td>\n",
       "      <td>275.964937</td>\n",
       "      <td>179.786747</td>\n",
       "      <td>188.534853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.43132</td>\n",
       "      <td>6.142564</td>\n",
       "      <td>...</td>\n",
       "      <td>545.964957</td>\n",
       "      <td>545.964957</td>\n",
       "      <td>81.470031</td>\n",
       "      <td>3.533009</td>\n",
       "      <td>DL</td>\n",
       "      <td>1.878405</td>\n",
       "      <td>5.923080</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SplitSort        seg_x         seg_y    Dist_Seg  Dist_MHWbay  \\\n",
       "66615      66615  677018.1595  4.509975e+06  230.000032    82.220969   \n",
       "85619      85619  687214.1370  4.514490e+06  345.696325  -131.024561   \n",
       "66511      66511  677044.7910  4.509796e+06   55.000040   286.701757   \n",
       "31938      31938  657490.3763  4.501733e+06  434.999996   137.250023   \n",
       "87919      87919  688190.4957  4.514639e+06  270.000020   275.964937   \n",
       "\n",
       "        DistSegDH   DistSegDL  DistSegArm      ptZ     ptSlp     ...       \\\n",
       "66615  143.009575  149.259519         NaN  0.60388  2.552202     ...        \n",
       "85619  229.025318  240.263141         NaN  0.35092  0.961539     ...        \n",
       "66511   32.017383   25.841729         NaN  1.81084  2.832443     ...        \n",
       "31938         NaN         NaN         NaN  0.76025       NaN     ...        \n",
       "87919  179.786747  188.534853         NaN  5.43132  6.142564     ...        \n",
       "\n",
       "        WidthLand   WidthFull         uBW       uBH ub_feat mean_Zmhw  \\\n",
       "66615  312.221001  312.221001   80.787403  3.090523      DL  0.957232   \n",
       "85619  749.924166  855.620515  105.471719  4.944896      DL  0.591762   \n",
       "66511  341.701797  341.701797   80.572297  2.878211      DL  0.657066   \n",
       "31938  572.250019  572.250019         NaN       NaN     NaN       NaN   \n",
       "87919  545.964957  545.964957   81.470031  3.533009      DL  1.878405   \n",
       "\n",
       "       max_Zmhw  Construction  Development  Nourishment  \n",
       "66615  4.469680         111.0        111.0        222.0  \n",
       "85619  7.122921         111.0        111.0        222.0  \n",
       "66511  3.999680         111.0        111.0        222.0  \n",
       "31938  3.859720         111.0        333.0        222.0  \n",
       "87919  5.923080         111.0        111.0        222.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recode the values for CSV\n",
    "pts_df4csv = pts_df.replace({'SubType': {7777:'{1111, 2222}', 1000:'{1111, 3333}'}, \n",
    "                              'VegType': {77:'{11, 22}', 88:'{22, 33}', 99:'{33, 44}'},\n",
    "                              'VegDens': {666: '{111, 222}', 777: '{222, 333}', \n",
    "                                          888: '{333, 444}', 999: '{222, 333, 444}'}})\n",
    "\n",
    "pts_df4csv.to_pickle(os.path.join(scratch_dir, transPts_null+'_4csv.pkl'))\n",
    "\n",
    "pts_df4csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: \\\\Mac\\stor\\Projects\\TransectExtraction\\FireIsland2012\\scratch\\FireIsland2012_transPts_fill.csv\n",
      "No Excel file created. You'll have to do it yourself from the CSV.\n"
     ]
    }
   ],
   "source": [
    "# pID_fld needs to be among the columns\n",
    "if not pID_fld in pts_df4csv.columns:\n",
    "    pts_df4csv.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Save CSV in scratch_dir\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df4csv.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))\n",
    "\n",
    "try:\n",
    "    xls_fname = os.path.join(scratch_dir, transPts_fill +'.xlsx')\n",
    "    pts_df4csv.to_excel(xls_fname, na_rep=fill, index=False)\n",
    "    print(\"OUTPUT: {}\".format(xls_fname))\n",
    "except:\n",
    "    print(\"No Excel file created. You'll have to do it yourself from the CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n"
     ]
    }
   ],
   "source": [
    "tr_w_LRR = os.path.join(arcpy.env.workspace, 'fiis_trans_wLRR')\n",
    "trans_df3 = fwa.FCtoDF(tr_w_LRR, id_fld=tID_fld, dffields=['LRR'])\n",
    "\n",
    "# Load dataframes\n",
    "trans_df= pd.read_pickle(os.path.join(scratch_dir, '20180108', extTrans_null+'_anthro.pkl'))\n",
    "pts_df= pd.read_pickle(os.path.join(scratch_dir, '20180108', transPts_null+'_anthro.pkl'))\n",
    "\n",
    "# Join anthro fields to trans and points DFs\n",
    "trans_df = fun.join_columns(trans_df, trans_df3) \n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "\n",
    "# Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_anthroLRR.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'_anthroLRR.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: \\\\Mac\\stor\\Projects\\TransectExtraction\\FireIsland2012\\scratch\\FireIsland2012_transPts_fill.csv\n"
     ]
    }
   ],
   "source": [
    "# Sort columns\n",
    "pts_df = pts_df.reindex_axis(sorted_pt_flds, axis=1)\n",
    "\n",
    "# Recode\n",
    "pts_df4csv = pts_df.replace({'GeoSet': {9999:-99999},\n",
    "                             'SubType': {7777:'{1111, 2222}', 1000:'{1111, 3333}', 9999:-99999}, \n",
    "                              'VegType': {77:'{11, 22}', 88:'{22, 33}', 99:'{33, 44}', 9999:-99999},\n",
    "                              'VegDens': {666: '{111, 222}', 777: '{222, 333}', \n",
    "                                          888: '{333, 444}', 999: '{222, 333, 444}', 9999:-99999}})\n",
    "\n",
    "# Save as pickle\n",
    "pts_df4csv.to_pickle(os.path.join(scratch_dir, transPts_null+'_4csv.pkl'))\n",
    "\n",
    "# Save as CSV\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df4csv.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troubleshooting ArmorLineToTrans_PD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: Rockaway\n",
      "year: 2014\n",
      "Path to project directory (e.g. \\\\Mac\u000b",
      "olume\\dir\\FireIsland2014): \\\\Mac\\stor\\Projects\\TransectExtraction\\Rockaway2014\n",
      "setvars.py initialized variables.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import core.functions_warcpy as fwa\n",
    "import core.functions as fun\n",
    "\n",
    "from core.setvars import *\n",
    "\n",
    "armorLines = os.path.join(home, 'BP_armorshoreward_2014')\n",
    "sl2trans_df = pd.read_pickle(os.path.join(scratch_dir, 'sl2trans.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array with X and Y...\n",
      "Converting array to dataframe...\n"
     ]
    }
   ],
   "source": [
    "flds = ['Arm_x', 'Arm_y', 'Arm_z']\n",
    "arm2trans = os.path.join(arcpy.env.scratchGDB, \"arm2trans\")\n",
    "\n",
    "df = fwa.FCtoDF(arm2trans, xy=True, dffields=[tID_fld, 'Arm_z'])\n",
    "df.index = df.pop(tID_fld)\n",
    "df.rename(columns={'SHAPE@X':'Arm_x','SHAPE@Y':'Arm_y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 375\n",
    "sl = sl2trans_df.loc[i, :] # get shoreline point at transect #FIXME: what happens if there's no shoreline point\n",
    "rows = df.loc[i,:] # get rows with duplicated transect ID\n",
    "rows = rows.assign(bw = lambda x: np.hypot(sl.SL_x - x.Arm_x, sl.SL_y - x.Arm_y)) # calculate dist from SL to each point in row (bw) #FIXME: 'Series' object has no attribute 'assign'\n",
    "df.drop(i, axis=0, inplace=True)\n",
    "df = pd.concat([df, rows.loc[rows['bw'] == min(rows['bw']), flds]]) # return the row with the smallest bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-68a7274ccac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl2trans_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# get shoreline point at transect #FIXME: what happens if there's no shoreline point\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# get rows with duplicated transect ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSL_x\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArm_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSL_y\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArm_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculate dist from SL to each point in row (bw) #FIXME: 'Series' object has no attribute 'assign'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bw'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bw'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# return the row with the smallest bw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2970\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2972\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "if df.index.duplicated().any():\n",
    "    idx = df.index[df.index.duplicated()]\n",
    "    for i in idx:\n",
    "        sl = sl2trans_df.loc[i, :] # get shoreline point at transect #FIXME: what happens if there's no shoreline point\n",
    "        rows = df.loc[i,:] # get rows with duplicated transect ID\n",
    "        rows = rows.assign(bw = lambda x: np.hypot(sl.SL_x - x.Arm_x, sl.SL_y - x.Arm_y)) # calculate dist from SL to each point in row (bw) #FIXME: 'Series' object has no attribute 'assign'\n",
    "        df.drop(i, axis=0, inplace=True)\n",
    "        df = pd.concat([df, rows.loc[rows['bw'] == min(rows['bw']), flds]]) # return the row with the smallest bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm_x    6.068042e+05\n",
       "Arm_y    4.494528e+06\n",
       "Arm_z    7.504399e-01\n",
       "Name: 375, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = df.index[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arm_x    6.068042e+05\n",
       "Arm_y    4.494528e+06\n",
       "Arm_z    7.504399e-01\n",
       "Name: 375, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SL_x      6.068051e+05\n",
       "SL_y      4.494525e+06\n",
       "Bslope             NaN\n",
       "Name: 375, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl2trans_df.loc[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why is it entering this conditional statement? It should be false... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
       "            ...\n",
       "             87,  88,  89,  90,  91,  92,  74,  77,  78, 375],\n",
       "           dtype='int64', name='sort_ID', length=297)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=flds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if df.index.duplicated().any():\n",
    "    print('we entered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-9bfc9193668f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-9bfc9193668f>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    Arm_z          Arm_x         Arm_y\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rows = pd.DataFrame(data={'z': [1.7, 0.7, 0.75],\n",
    "                    'x':[802, 803, 804],\n",
    "                    'y':[538, 530, 528]}, \n",
    "                   index={'sort_ID': [375, 375, 375]})\n",
    "\n",
    "Arm_z          Arm_x         Arm_y\n",
    "sort_ID                                      \n",
    "375      1.77656  606802.057020  4.494538e+06\n",
    "375      0.73352  606803.958755  4.494530e+06\n",
    "375      0.75044  606804.225982  4.494528e+06\n",
    "Arm_x    6.068042e+05\n",
    "Arm_y    4.494528e+06\n",
    "Arm_z    7.504399e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [405, 405, 312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a464c7d3d9e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "idx.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
